{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyhYf1izIVUO"
      },
      "source": [
        "# **Project Overview**\n",
        "\n",
        "**Objective**\n",
        "\n",
        "Develop a neural network that:\n",
        "\n",
        "Learns to translate mathematical expressions from infix notation (e.g., a + b * c) to postfix notation (e.g., a b c * +).\n",
        "Handles syntactic ambiguity using a data-driven method rather than rule-based parsing.\n",
        "Operates on symbolic sequences using encoder-decoder or autoregressive modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duv50vWJI3ET"
      },
      "source": [
        "# **Constraints**\n",
        "* Input: infix expressions (with parentheses and operators).\n",
        "* Output: correctly disambiguated postfix expressions.\n",
        "* Maximum syntactic depth of expressions: 3\n",
        "* Vocabulary: limited to symbols, operators, parentheses, and variables a–e.\n",
        "* Model: ≤ 2 million parameters\n",
        "* No beam search; only greedy autoregressive decoding\n",
        "* Evaluation: prefix accuracy, not exact match"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTTfZ3aiJtca"
      },
      "source": [
        "# **Overall Architecture**\n",
        "\n",
        "A LSTM-based sequence-to-sequence architecture:\n",
        "\n",
        "* Encoder: Encodes infix expression\n",
        "* Decoder: Generates postfix expression step by step\n",
        "\n",
        "Use teacher forcing during training, autoregressive decoding during inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUjHT9Z-J8Oy"
      },
      "source": [
        "# **Project Structure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Ay8CE9K6Ob"
      },
      "source": [
        "# Step 1: Dataset Creation\n",
        "\n",
        "\n",
        "1. Constants & Vocabulary (limited to depth 3)\n",
        "2. Generate Infix Expression\n",
        "3. Tokenization\n",
        "4. Infix to Postfix Conversion\n",
        "5. Encoding & Decoding\n",
        "6. Dataset Generator\n",
        "7. Shifted Decoder Input (for teacher forcing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F0i-KdiMPix"
      },
      "source": [
        "**1.1. Constants & Vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qs430Df5LnCc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "OPERATORS = ['+', '-', '*', '/']\n",
        "IDENTIFIERS = list('abcde')\n",
        "SPECIAL_TOKENS = ['PAD', 'SOS', 'EOS']\n",
        "SYMBOLS = ['(', ')', '+', '-', '*', '/']\n",
        "VOCAB = SPECIAL_TOKENS + SYMBOLS + IDENTIFIERS + ['JUNK']\n",
        "\n",
        "token_to_id = {tok: i for i, tok in enumerate(VOCAB)}\n",
        "id_to_token = {i: tok for tok, i in token_to_id.items()}\n",
        "\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "PAD_ID = token_to_id['PAD']\n",
        "SOS_ID = token_to_id['SOS']\n",
        "EOS_ID = token_to_id['EOS']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMtTSBbZMXiV"
      },
      "source": [
        "**1.2. Generate Infix Expression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZGF38bp7LrfT"
      },
      "outputs": [],
      "source": [
        "def generate_infix_expression(max_depth):\n",
        "    if max_depth == 0:\n",
        "        return random.choice(IDENTIFIERS)\n",
        "    elif random.random() < 0.5:\n",
        "        return generate_infix_expression(max_depth - 1)\n",
        "    else:\n",
        "        left = generate_infix_expression(max_depth - 1)\n",
        "        right = generate_infix_expression(max_depth - 1)\n",
        "        op = random.choice(OPERATORS)\n",
        "        return f'({left} {op} {right})'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV2WAbp_McZK"
      },
      "source": [
        "**1.3. Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nRZgHADJLvtE"
      },
      "outputs": [],
      "source": [
        "def tokenize(expr):\n",
        "    return [c for c in expr if c in token_to_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzIMAZBvMfMk"
      },
      "source": [
        "**1.4. Infix to Postfix Conversion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pKkoLW_2Mlnb"
      },
      "outputs": [],
      "source": [
        "def infix_to_postfix(tokens):\n",
        "    precedence = {'+': 1, '-': 1, '*': 2, '/': 2}\n",
        "    output, stack = [], []\n",
        "    for token in tokens:\n",
        "        if token in IDENTIFIERS:\n",
        "            output.append(token)\n",
        "        elif token in OPERATORS:\n",
        "            while stack and stack[-1] in OPERATORS and precedence[stack[-1]] >= precedence[token]:\n",
        "                output.append(stack.pop())\n",
        "            stack.append(token)\n",
        "        elif token == '(':\n",
        "            stack.append(token)\n",
        "        elif token == ')':\n",
        "            while stack and stack[-1] != '(':\n",
        "                output.append(stack.pop())\n",
        "            stack.pop()\n",
        "    while stack:\n",
        "        output.append(stack.pop())\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVHIADU8Ml5O"
      },
      "source": [
        "**1.5. Encoding & Decoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pRgR69T8MpUv"
      },
      "outputs": [],
      "source": [
        "MAX_DEPTH = 3\n",
        "MAX_LEN = 4 * 2**MAX_DEPTH - 2  # Safe upper bound for postfix len\n",
        "\n",
        "def encode(tokens, max_len=MAX_LEN):\n",
        "    ids = [token_to_id[t] for t in tokens] + [EOS_ID]\n",
        "    return ids + [PAD_ID] * (max_len - len(ids))\n",
        "\n",
        "def decode_sequence(token_ids, id_to_token, pad_token='PAD', eos_token='EOS'):\n",
        "    tokens = []\n",
        "    for token_id in token_ids:\n",
        "        token = id_to_token.get(token_id, '?')\n",
        "        if token == eos_token:\n",
        "            break\n",
        "        if token != pad_token:\n",
        "            tokens.append(token)\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uc9neIHMplS"
      },
      "source": [
        "**1.6. Dataset Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "AzvfvfHZMthm"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(n, max_depth=MAX_DEPTH):\n",
        "    X, Y = [], []\n",
        "    for _ in range(n):\n",
        "        expr = generate_infix_expression(max_depth)\n",
        "        infix = tokenize(expr)\n",
        "        postfix = infix_to_postfix(infix)\n",
        "        X.append(encode(infix))\n",
        "        Y.append(encode(postfix))\n",
        "    return np.array(X), np.array(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT1SlksXNV57"
      },
      "source": [
        "**1.7. Shifted Decoder Input (for teacher forcing)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "E5c8POWDNWSO"
      },
      "outputs": [],
      "source": [
        "def shift_right(seqs):\n",
        "    shifted = np.zeros_like(seqs)\n",
        "    shifted[:, 1:] = seqs[:, :-1]\n",
        "    shifted[:, 0] = SOS_ID\n",
        "    return shifted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbxuHsAaNk87"
      },
      "source": [
        "**1.8. Example Usage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7hiYl_aNpOE",
        "outputId": "5653ab41-af4b-48f1-d155-6b77d7a25437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 7809\n",
            "Infix  : ( ( c - e ) + a )\n",
            "Postfix: c e - a +\n",
            "Shifted: SOS c e - a +\n"
          ]
        }
      ],
      "source": [
        "# Create training and validation data\n",
        "X_train, Y_train = generate_dataset(10000)\n",
        "decoder_input_train = shift_right(Y_train)\n",
        "\n",
        "X_val, Y_val = generate_dataset(1000)\n",
        "decoder_input_val = shift_right(Y_val)\n",
        "\n",
        "# Sanity check\n",
        "i = np.random.randint(10000)\n",
        "print(\"Example\", i)\n",
        "print(\"Infix  :\", decode_sequence(X_train[i], id_to_token))\n",
        "print(\"Postfix:\", decode_sequence(Y_train[i], id_to_token))\n",
        "print(\"Shifted:\", decode_sequence(decoder_input_train[i], id_to_token))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFQ1rB1bh09z"
      },
      "source": [
        "# Step 2: LSTM Encoder-Decoder Architecture\n",
        "We will implement a simple sequence-to-sequence model using:\n",
        "\n",
        "* An encoder (LSTM) that processes the infix sequence\n",
        "* A decoder (LSTM) that generates postfix tokens autoregressively\n",
        "* A shared embedding layer\n",
        "\n",
        "This architecture respects the < 2 million parameter constraint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E37i523niZiQ"
      },
      "source": [
        "**2.1. Define Model Inputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Arz4mJ00h27i"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "import gdown\n",
        "\n",
        "# Download pretrained weights\n",
        "gdown.download(id=\"1ZI89h7LchbNfQ3w_FXzZd-WBX4P57qfn\", output=\"model_weights.weights.h5\", quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "EX7wthYLWJlH",
        "outputId": "01e365c0-f92f-4781-abe1-656440e04fa1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZI89h7LchbNfQ3w_FXzZd-WBX4P57qfn\n",
            "To: /content/model_weights.weights.h5\n",
            "100%|██████████| 2.44M/2.44M [00:00<00:00, 164MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_weights.weights.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpFnw5x4ijrE"
      },
      "source": [
        "**2.2. Architecture Definition**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following function -masked_accuracy- is implemented to provide a more truthful measure of model performance by excluding PAD tokens from the accuracy calculation. Unlike standard accuracy, which can be inflated by padding, masked_accuracy reflects only the correctness of actual predicted tokens, leading to a more reliable evaluation of the model’s ability to generate valid postfix expressions."
      ],
      "metadata": {
        "id": "Fq9QgrO83Qxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4xg7GtHOikAA"
      },
      "outputs": [],
      "source": [
        "def masked_accuracy(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true, axis=-1)  # shape: (batch_size, seq_len)\n",
        "    y_pred_labels = tf.argmax(y_pred, axis=-1)\n",
        "\n",
        "    # Mask out PAD positions\n",
        "    mask = tf.cast(tf.not_equal(y_true, PAD_ID), tf.float32)\n",
        "    match = tf.cast(tf.equal(y_true, y_pred_labels), tf.float32)\n",
        "\n",
        "    accuracy = tf.reduce_sum(match * mask) / tf.reduce_sum(mask)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The implemented model for this project is a classic encoder-decoder architecture using shared embedding layers and LSTM units for sequence-to-sequence translation. The encoder processes the input infix sequence into context states, which are then used to initialize the decoder for generating the corresponding postfix sequence."
      ],
      "metadata": {
        "id": "OmhR0fhZ5Lf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "EMBEDDING_DIM = 64\n",
        "LATENT_DIM = 128\n",
        "\n",
        "# Shared embedding\n",
        "embedding_layer = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, mask_zero=True)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(MAX_LEN,), name=\"encoder_input\")\n",
        "encoder_embedded = embedding_layer(encoder_inputs)\n",
        "encoder_lstm = LSTM(LATENT_DIM, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(encoder_embedded)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(MAX_LEN,), name=\"decoder_input\")\n",
        "decoder_embedded = embedding_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=[state_h, state_c])\n",
        "\n",
        "# Output layer\n",
        "decoder_dense = Dense(VOCAB_SIZE, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Full model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "# model.compile(optimizer=Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[masked_accuracy])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "R_SUPO3j3DLu",
        "outputId": "12facc89-bff4-488e-9b04-54705842f87d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m960\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │     \u001b[38;5;34m98,816\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m), │     \u001b[38;5;34m98,816\u001b[0m │ embedding_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m15\u001b[0m)    │      \u001b[38;5;34m1,935\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m200,527\u001b[0m (783.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,527</span> (783.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m200,527\u001b[0m (783.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,527</span> (783.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2A-xlPoiqfR"
      },
      "source": [
        "**2.3. Prepare Targets for Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DBpd2VB8iq4c"
      },
      "outputs": [],
      "source": [
        "# Sparse categorical crossentropy needs 3D input for Y\n",
        "Y_train_expanded = np.expand_dims(Y_train, axis=-1)\n",
        "Y_val_expanded = np.expand_dims(Y_val, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq01DK9xi3dt"
      },
      "source": [
        "**2.4. Train the Model \\ Load pretrained weights**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"model_weights.weights.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSF30YCOVMbQ",
        "outputId": "3d3f0f16-01a3-40d9-8934-7e3c22b970c7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 20 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2O_pgTxi32D",
        "outputId": "733c63f6-6698-433e-b73e-47f259b35a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 1.9412 - masked_accuracy: 0.2448 - val_loss: 1.2871 - val_masked_accuracy: 0.3897\n",
            "Epoch 2/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 1.1738 - masked_accuracy: 0.4660 - val_loss: 0.7049 - val_masked_accuracy: 0.7154\n",
            "Epoch 3/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.6107 - masked_accuracy: 0.7528 - val_loss: 0.3895 - val_masked_accuracy: 0.8507\n",
            "Epoch 4/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3494 - masked_accuracy: 0.8717 - val_loss: 0.2447 - val_masked_accuracy: 0.9148\n",
            "Epoch 5/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2252 - masked_accuracy: 0.9238 - val_loss: 0.1716 - val_masked_accuracy: 0.9447\n",
            "Epoch 6/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1559 - masked_accuracy: 0.9524 - val_loss: 0.1207 - val_masked_accuracy: 0.9619\n",
            "Epoch 7/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1212 - masked_accuracy: 0.9638 - val_loss: 0.0942 - val_masked_accuracy: 0.9719\n",
            "Epoch 8/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0826 - masked_accuracy: 0.9779 - val_loss: 0.0771 - val_masked_accuracy: 0.9769\n",
            "Epoch 9/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0682 - masked_accuracy: 0.9818 - val_loss: 0.0600 - val_masked_accuracy: 0.9837\n",
            "Epoch 10/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0559 - masked_accuracy: 0.9849 - val_loss: 0.0621 - val_masked_accuracy: 0.9816\n",
            "Epoch 11/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0493 - masked_accuracy: 0.9869 - val_loss: 0.0538 - val_masked_accuracy: 0.9849\n",
            "Epoch 12/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0454 - masked_accuracy: 0.9878 - val_loss: 0.0393 - val_masked_accuracy: 0.9887\n",
            "Epoch 13/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0318 - masked_accuracy: 0.9930 - val_loss: 0.0428 - val_masked_accuracy: 0.9869\n",
            "Epoch 14/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0280 - masked_accuracy: 0.9942 - val_loss: 0.0381 - val_masked_accuracy: 0.9884\n",
            "Epoch 15/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0242 - masked_accuracy: 0.9950 - val_loss: 0.0274 - val_masked_accuracy: 0.9926\n",
            "Epoch 16/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0208 - masked_accuracy: 0.9958 - val_loss: 0.0264 - val_masked_accuracy: 0.9925\n",
            "Epoch 17/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0154 - masked_accuracy: 0.9979 - val_loss: 0.0265 - val_masked_accuracy: 0.9915\n",
            "Epoch 18/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0210 - masked_accuracy: 0.9953 - val_loss: 0.0184 - val_masked_accuracy: 0.9961\n",
            "Epoch 19/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0125 - masked_accuracy: 0.9981 - val_loss: 0.0162 - val_masked_accuracy: 0.9958\n",
            "Epoch 20/20\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0203 - masked_accuracy: 0.9944 - val_loss: 0.0273 - val_masked_accuracy: 0.9901\n"
          ]
        }
      ],
      "source": [
        "# history = model.fit(\n",
        "#     [X_train, decoder_input_train],\n",
        "#     Y_train_expanded,\n",
        "#     validation_data=([X_val, decoder_input_val], Y_val_expanded),\n",
        "#     epochs=20,\n",
        "#     batch_size=64\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnnxxb52j0t-"
      },
      "source": [
        "# Step 3: Autoregressive Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tk9gwL_kDuI"
      },
      "source": [
        "**3.1. Define Inference Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The encoder model outputs the final LSTM states (state_h, state_c), which summarize the input sequence. During inference, the decoder model generates one token at a time using the previous hidden states and input token, enabling step-by-step sequence generation."
      ],
      "metadata": {
        "id": "uVRLl9PC5gnf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "B3oAHGlukAsJ"
      },
      "outputs": [],
      "source": [
        "# Encoder model\n",
        "encoder_model = Model(encoder_inputs, [state_h, state_c])\n",
        "\n",
        "# Decoder for inference\n",
        "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
        "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
        "decoder_input_single = Input(shape=(1,))  # one token at a time\n",
        "\n",
        "decoder_embedded_inf = embedding_layer(decoder_input_single)\n",
        "decoder_outputs_inf, h, c = decoder_lstm(\n",
        "    decoder_embedded_inf, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        ")\n",
        "decoder_output_token = decoder_dense(decoder_outputs_inf)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_input_single, decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_output_token, h, c]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vclFWhLlkHdC"
      },
      "source": [
        "**3.2. Autoregressive Decode Function**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function performs token-by-token inference by initializing the decoder with the encoder's final states and a <SOS> token. It iteratively predicts the next token until it generates <EOS> or reaches the maximum length, returning the decoded token sequence."
      ],
      "metadata": {
        "id": "R8VTEv185r7b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "whhkXkfikKmk"
      },
      "outputs": [],
      "source": [
        "def autoregressive_decode(input_seq):\n",
        "    h, c = encoder_model.predict(input_seq.reshape(1, -1), verbose=0)\n",
        "    target_seq = np.zeros((1, 1), dtype=np.int32)\n",
        "    target_seq[0, 0] = SOS_ID\n",
        "\n",
        "    decoded_tokens = []\n",
        "    for _ in range(MAX_LEN):\n",
        "        output, h, c = decoder_model.predict([target_seq, h, c], verbose=0)\n",
        "        token_id = np.argmax(output[0, 0])\n",
        "        token = id_to_token[token_id]\n",
        "        if token == 'EOS':\n",
        "            break\n",
        "        decoded_tokens.append(token)\n",
        "        target_seq[0, 0] = token_id\n",
        "    return [token_to_id[t] for t in decoded_tokens if t in token_to_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2WW4GElkNMQ"
      },
      "source": [
        "**3.3. Try an Example**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YNKE1yRkNl1",
        "outputId": "3b891a98-fa71-4ff3-9fd5-7798e962eb9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infix        : ( ( e + c ) + ( c / b ) )\n",
            "Target Postfix: e c + c b / +\n",
            "Predicted     : e c + c b / +\n"
          ]
        }
      ],
      "source": [
        "idx = np.random.randint(len(X_val))\n",
        "x_sample = X_val[idx]\n",
        "y_true = Y_val[idx]\n",
        "y_pred = autoregressive_decode(x_sample)\n",
        "\n",
        "print(\"Infix        :\", decode_sequence(x_sample, id_to_token))\n",
        "print(\"Target Postfix:\", decode_sequence(y_true, id_to_token))\n",
        "print(\"Predicted     :\", decode_sequence(y_pred, id_to_token))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52E8gL7ekyBK"
      },
      "source": [
        "# Step 4: Prefix Accuracy Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cOkw7cykyc5"
      },
      "source": [
        "**4.1. Function: prefix_accuracy_single**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "AtbteDDrky3J"
      },
      "outputs": [],
      "source": [
        "def prefix_accuracy_single(y_true, y_pred, id_to_token, eos_id=EOS_ID, verbose=False):\n",
        "    t_str = decode_sequence(y_true, id_to_token).split(' EOS')[0]\n",
        "    p_str = decode_sequence(y_pred, id_to_token).split(' EOS')[0]\n",
        "    t_tokens = t_str.strip().split()\n",
        "    p_tokens = p_str.strip().split()\n",
        "\n",
        "    max_len = max(len(t_tokens), len(p_tokens))\n",
        "    match_len = sum(x == y for x, y in zip(t_tokens, p_tokens))\n",
        "\n",
        "    score = match_len / max_len if max_len > 0 else 0\n",
        "\n",
        "    if verbose:\n",
        "        print(\"TARGET  :\", ' '.join(t_tokens))\n",
        "        print(\"PREDICT :\", ' '.join(p_tokens))\n",
        "        print(f\"MATCH   : {match_len}/{max_len} → {score:.2f}\")\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEoJ6TdVlP1Y"
      },
      "source": [
        "**4.2. Function: test()**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rwIRrb0glQJp"
      },
      "outputs": [],
      "source": [
        "def test(n=20, rounds=10):\n",
        "    results = []\n",
        "    for r in range(rounds):\n",
        "        print(f\"Round {r+1}\")\n",
        "        X_test, Y_test = generate_dataset(n)\n",
        "        scores = []\n",
        "        for i in range(n):\n",
        "            x = X_test[i]\n",
        "            y_true = Y_test[i]\n",
        "            y_pred = autoregressive_decode(x)\n",
        "            score = prefix_accuracy_single(y_true, y_pred, id_to_token)\n",
        "            scores.append(score)\n",
        "        avg = np.mean(scores)\n",
        "        print(f\"  Average prefix accuracy: {avg:.3f}\")\n",
        "        results.append(avg)\n",
        "    return np.mean(results), np.std(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2MH4vKMlFGW"
      },
      "source": [
        "**4.3. Run Evaluationt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHLe8G72lFYn",
        "outputId": "b93a78c3-93dd-445f-9a88-1d6c4d12cdd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1\n",
            "  Average prefix accuracy: 0.981\n",
            "Round 2\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 3\n",
            "  Average prefix accuracy: 0.986\n",
            "Round 4\n",
            "  Average prefix accuracy: 0.991\n",
            "Round 5\n",
            "  Average prefix accuracy: 0.997\n",
            "Round 6\n",
            "  Average prefix accuracy: 0.992\n",
            "Round 7\n",
            "  Average prefix accuracy: 0.977\n",
            "Round 8\n",
            "  Average prefix accuracy: 0.989\n",
            "Round 9\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 10\n",
            "  Average prefix accuracy: 0.975\n",
            "\n",
            "Final Prefix Accuracy: 0.989 ± 0.008\n"
          ]
        }
      ],
      "source": [
        "mean_score, std_dev = test(n=20, rounds=10)\n",
        "print(f\"\\nFinal Prefix Accuracy: {mean_score:.3f} ± {std_dev:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "During this project, I implemented and evaluated multiple architectures for the infix-to-postfix translation task, including:\n",
        "\n",
        "**Transformer-based Encoder-Decoder**\n",
        "* Achieved: Final Prefix Accuracy = 1.000 ± 0.000\n",
        "* Parameters: >1.5 million\n",
        "* Pros: High accuracy\n",
        "* Cons: High computational cost, slower training\n",
        "\n",
        "**Seq2Seq with Luong-style Attention**\n",
        "* Achieved: Final Prefix Accuracy = 1.000 ± 0.000\n",
        "* Parameters: ~800,000\n",
        "* Pros: High accuracy\n",
        "* Cons: Moderate complexity, slower than non-attention models\n",
        "\n",
        "**Final Chosen Model – LSTM-based Seq2Seq without Attention**\n",
        "* Achieved: Final Prefix Accuracy = 0.989 ± 0.008\n",
        "* Parameters: ~200,000\n",
        "* Pros:\n",
        "     * Lightweight and efficient\n",
        "     * Fast training and inference\n",
        "     * Easier to interpret and deploy\n",
        "* Cons:\n",
        "     * Slightly lower accuracy\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "Despite the slightly lower accuracy, I chose the LSTM-based Seq2Seq model without attention due to its significantly reduced complexity, faster performance, and minimal resource requirements, making it ideal for real-world deployment scenarios."
      ],
      "metadata": {
        "id": "uzSjM8ap_-GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new unseen test dataset\n",
        "X_test_new, Y_test_new = generate_dataset(n=1000, max_depth=MAX_DEPTH)\n",
        "def evaluate_on_dataset(X_data, Y_data, sample_count=20, verbose=False):\n",
        "    scores = []\n",
        "    for i in range(sample_count):\n",
        "        x = X_data[i]\n",
        "        y_true = Y_data[i]\n",
        "        y_pred = autoregressive_decode(x)\n",
        "        score = prefix_accuracy_single(y_true, y_pred, id_to_token, verbose=verbose)\n",
        "        scores.append(score)\n",
        "    return np.mean(scores), np.std(scores)\n",
        "mean_new, std_new = evaluate_on_dataset(X_test_new, Y_test_new, sample_count=100, verbose=False)\n",
        "print(f\"New Test Set Prefix Accuracy: {mean_new:.3f} ± {std_new:.3f}\")\n",
        "for _ in range(5):\n",
        "    i = np.random.randint(len(X_test_new))\n",
        "    print(f\"\\nExample {i}\")\n",
        "    print(\"Infix       :\", decode_sequence(X_test_new[i], id_to_token))\n",
        "    print(\"True Postfix:\", decode_sequence(Y_test_new[i], id_to_token))\n",
        "    print(\"Predicted   :\", decode_sequence(autoregressive_decode(X_test_new[i]), id_to_token))\n",
        "    print('-' * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHo0duZkLWOS",
        "outputId": "6e6777c4-97c1-48f2-c2f2-5bd4291cec1f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Test Set Prefix Accuracy: 0.994 ± 0.028\n",
            "\n",
            "Example 800\n",
            "Infix       : ( c / e )\n",
            "True Postfix: c e /\n",
            "Predicted   : c e /\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 982\n",
            "Infix       : ( e * e )\n",
            "True Postfix: e e *\n",
            "Predicted   : e e *\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 672\n",
            "Infix       : ( a - ( c * a ) )\n",
            "True Postfix: a c a * -\n",
            "Predicted   : a c a * -\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 743\n",
            "Infix       : ( d * e )\n",
            "True Postfix: d e *\n",
            "Predicted   : d e *\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 994\n",
            "Infix       : ( ( d / e ) - a )\n",
            "True Postfix: d e / a -\n",
            "Predicted   : d e / a -\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "o4Ay8CE9K6Ob",
        "Tnnxxb52j0t-"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}