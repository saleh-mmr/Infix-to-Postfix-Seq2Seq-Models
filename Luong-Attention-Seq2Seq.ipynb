{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyhYf1izIVUO"
      },
      "source": [
        "# **Project Overview**\n",
        "\n",
        "**Objective**\n",
        "\n",
        "Develop a neural network that:\n",
        "\n",
        "Learns to translate mathematical expressions from infix notation (e.g., a + b * c) to postfix notation (e.g., a b c * +).\n",
        "Handles syntactic ambiguity using a data-driven method rather than rule-based parsing.\n",
        "Operates on symbolic sequences using encoder-decoder or autoregressive modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duv50vWJI3ET"
      },
      "source": [
        "# **Constraints**\n",
        "* Input: infix expressions (with parentheses and operators).\n",
        "* Output: correctly disambiguated postfix expressions.\n",
        "* Maximum syntactic depth of expressions: 3\n",
        "* Vocabulary: limited to symbols, operators, parentheses, and variables a–e.\n",
        "* Model: ≤ 2 million parameters\n",
        "* No beam search; only greedy autoregressive decoding\n",
        "* Evaluation: prefix accuracy, not exact match"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTTfZ3aiJtca"
      },
      "source": [
        "# **Overall Architecture**\n",
        "\n",
        "A sequence-to-sequence model is needed:\n",
        "\n",
        "* Encoder: Encodes infix expression\n",
        "* Decoder: Generates postfix expression step by step\n",
        "\n",
        "Use teacher forcing during training, autoregressive decoding during inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUjHT9Z-J8Oy"
      },
      "source": [
        "# **Project Structure and Steps**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Ay8CE9K6Ob"
      },
      "source": [
        "# Step 1: Dataset Creation\n",
        "\n",
        "\n",
        "1. Constants & Vocabulary (limited to depth 3)\n",
        "2. Generate Infix Expression\n",
        "3. Tokenization\n",
        "4. Infix to Postfix Conversion\n",
        "5. Encoding & Decoding\n",
        "6. Dataset Generator\n",
        "7. Shifted Decoder Input (for teacher forcing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F0i-KdiMPix"
      },
      "source": [
        "**1.1. Constants & Vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qs430Df5LnCc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "OPERATORS = ['+', '-', '*', '/']\n",
        "IDENTIFIERS = list('abcde')\n",
        "SPECIAL_TOKENS = ['PAD', 'SOS', 'EOS']\n",
        "SYMBOLS = ['(', ')', '+', '-', '*', '/']\n",
        "VOCAB = SPECIAL_TOKENS + SYMBOLS + IDENTIFIERS + ['JUNK']\n",
        "\n",
        "token_to_id = {tok: i for i, tok in enumerate(VOCAB)}\n",
        "id_to_token = {i: tok for tok, i in token_to_id.items()}\n",
        "\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "PAD_ID = token_to_id['PAD']\n",
        "SOS_ID = token_to_id['SOS']\n",
        "EOS_ID = token_to_id['EOS']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMtTSBbZMXiV"
      },
      "source": [
        "**1.2. Generate Infix Expression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZGF38bp7LrfT"
      },
      "outputs": [],
      "source": [
        "def generate_infix_expression(max_depth):\n",
        "    if max_depth == 0:\n",
        "        return random.choice(IDENTIFIERS)\n",
        "    elif random.random() < 0.5:\n",
        "        return generate_infix_expression(max_depth - 1)\n",
        "    else:\n",
        "        left = generate_infix_expression(max_depth - 1)\n",
        "        right = generate_infix_expression(max_depth - 1)\n",
        "        op = random.choice(OPERATORS)\n",
        "        return f'({left} {op} {right})'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV2WAbp_McZK"
      },
      "source": [
        "**1.3. Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nRZgHADJLvtE"
      },
      "outputs": [],
      "source": [
        "def tokenize(expr):\n",
        "    return [c for c in expr if c in token_to_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzIMAZBvMfMk"
      },
      "source": [
        "**1.4. Infix to Postfix Conversion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pKkoLW_2Mlnb"
      },
      "outputs": [],
      "source": [
        "def infix_to_postfix(tokens):\n",
        "    precedence = {'+': 1, '-': 1, '*': 2, '/': 2}\n",
        "    output, stack = [], []\n",
        "    for token in tokens:\n",
        "        if token in IDENTIFIERS:\n",
        "            output.append(token)\n",
        "        elif token in OPERATORS:\n",
        "            while stack and stack[-1] in OPERATORS and precedence[stack[-1]] >= precedence[token]:\n",
        "                output.append(stack.pop())\n",
        "            stack.append(token)\n",
        "        elif token == '(':\n",
        "            stack.append(token)\n",
        "        elif token == ')':\n",
        "            while stack and stack[-1] != '(':\n",
        "                output.append(stack.pop())\n",
        "            stack.pop()\n",
        "    while stack:\n",
        "        output.append(stack.pop())\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVHIADU8Ml5O"
      },
      "source": [
        "**1.5. Encoding & Decoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pRgR69T8MpUv"
      },
      "outputs": [],
      "source": [
        "MAX_DEPTH = 3\n",
        "MAX_LEN = 4 * 2**MAX_DEPTH - 2  # Safe upper bound for postfix len\n",
        "\n",
        "def encode(tokens, max_len=MAX_LEN):\n",
        "    ids = [token_to_id[t] for t in tokens] + [EOS_ID]\n",
        "    return ids + [PAD_ID] * (max_len - len(ids))\n",
        "\n",
        "def decode_sequence(token_ids, id_to_token, pad_token='PAD', eos_token='EOS'):\n",
        "    tokens = []\n",
        "    for token_id in token_ids:\n",
        "        token = id_to_token.get(token_id, '?')\n",
        "        if token == eos_token:\n",
        "            break\n",
        "        if token != pad_token:\n",
        "            tokens.append(token)\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uc9neIHMplS"
      },
      "source": [
        "**1.6. Dataset Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AzvfvfHZMthm"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(n, max_depth=MAX_DEPTH):\n",
        "    X, Y = [], []\n",
        "    for _ in range(n):\n",
        "        expr = generate_infix_expression(max_depth)\n",
        "        infix = tokenize(expr)\n",
        "        postfix = infix_to_postfix(infix)\n",
        "        X.append(encode(infix))\n",
        "        Y.append(encode(postfix))\n",
        "    return np.array(X), np.array(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT1SlksXNV57"
      },
      "source": [
        "**1.7. Shifted Decoder Input (for teacher forcing)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E5c8POWDNWSO"
      },
      "outputs": [],
      "source": [
        "def shift_right(seqs):\n",
        "    shifted = np.zeros_like(seqs)\n",
        "    shifted[:, 1:] = seqs[:, :-1]\n",
        "    shifted[:, 0] = SOS_ID\n",
        "    return shifted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbxuHsAaNk87"
      },
      "source": [
        "**1.8. Example Usage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7hiYl_aNpOE",
        "outputId": "1cf1142c-7848-49d2-e2f0-b713fafe2dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 2825\n",
            "Infix  : ( ( ( b + d ) + a ) - ( ( c / b ) + d ) )\n",
            "Postfix: b d + a + c b / d + -\n",
            "Shifted: SOS b d + a + c b / d + -\n"
          ]
        }
      ],
      "source": [
        "# Create training and validation data\n",
        "X_train, Y_train = generate_dataset(10000)\n",
        "decoder_input_train = shift_right(Y_train)\n",
        "\n",
        "X_val, Y_val = generate_dataset(1000)\n",
        "decoder_input_val = shift_right(Y_val)\n",
        "\n",
        "# Sanity check\n",
        "i = np.random.randint(10000)\n",
        "print(\"Example\", i)\n",
        "print(\"Infix  :\", decode_sequence(X_train[i], id_to_token))\n",
        "print(\"Postfix:\", decode_sequence(Y_train[i], id_to_token))\n",
        "print(\"Shifted:\", decode_sequence(decoder_input_train[i], id_to_token))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFQ1rB1bh09z"
      },
      "source": [
        "# Step 2: LSTM Encoder-Decoder Architecture\n",
        "We will implement a simple sequence-to-sequence model using:\n",
        "\n",
        "* An encoder (LSTM) that processes the infix sequence\n",
        "* A decoder (LSTM) that generates postfix tokens autoregressively\n",
        "* A shared embedding layer\n",
        "* No attention for now (optional for later)\n",
        "\n",
        "This architecture respects the < 2 million parameter constraint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E37i523niZiQ"
      },
      "source": [
        "**2.1. Define Model Inputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Arz4mJ00h27i"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dot, Activation\n",
        "from tensorflow.keras.layers import Attention, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpFnw5x4ijrE"
      },
      "source": [
        "**2.2. Architecture Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "4xg7GtHOikAA",
        "outputId": "aa4e1f9d-bf16-40d9-fc48-8f0bd83ece15"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ shared_embedding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m1,920\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m394,240\u001b[0m │ shared_embedding… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m394,240\u001b[0m │ shared_embedding… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot_4 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dot_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot_5 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dot_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_projection   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m15\u001b[0m)    │      \u001b[38;5;34m7,695\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ shared_embedding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ shared_embedding… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ shared_embedding… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dot_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_projection   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,695</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m798,095\u001b[0m (3.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">798,095</span> (3.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m798,095\u001b[0m (3.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">798,095</span> (3.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Dimensions\n",
        "EMBEDDING_DIM = 128\n",
        "LATENT_DIM = 256\n",
        "\n",
        "# ---------------------- Encoder ----------------------\n",
        "encoder_inputs = Input(shape=(MAX_LEN,), name=\"encoder_input\")\n",
        "embedding_layer = Embedding(VOCAB_SIZE, EMBEDDING_DIM, mask_zero=True, name=\"shared_embedding\")\n",
        "encoder_embedding = embedding_layer(encoder_inputs)\n",
        "\n",
        "encoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True, name=\"encoder_lstm\")\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "\n",
        "# ---------------------- Decoder ----------------------\n",
        "decoder_inputs = Input(shape=(MAX_LEN,), name=\"decoder_input\")\n",
        "decoder_embedding = embedding_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
        "decoder_lstm_output, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "\n",
        "# ---------------------- Attention ----------------------\n",
        "# Compute attention scores (dot product)\n",
        "attention_scores = Dot(axes=[2, 2])([decoder_lstm_output, encoder_outputs])\n",
        "attention_weights = Activation('softmax')(attention_scores)\n",
        "\n",
        "# Weighted sum of encoder outputs\n",
        "attention_output = Dot(axes=[2, 1])([attention_weights, encoder_outputs])\n",
        "\n",
        "\n",
        "# Concatenate context + decoder output\n",
        "decoder_combined_context = Concatenate(axis=-1)([decoder_lstm_output, attention_output])\n",
        "\n",
        "# ---------------------- Output Projection ----------------------\n",
        "output_layer = Dense(VOCAB_SIZE, activation=\"softmax\", name=\"output_projection\")\n",
        "decoder_outputs = output_layer(decoder_combined_context)\n",
        "\n",
        "# ---------------------- Full Model ----------------------\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2A-xlPoiqfR"
      },
      "source": [
        "**2.3. Prepare Targets for Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DBpd2VB8iq4c"
      },
      "outputs": [],
      "source": [
        "# Sparse categorical crossentropy needs 3D input for Y\n",
        "Y_train_expanded = np.expand_dims(Y_train, axis=-1)\n",
        "Y_val_expanded = np.expand_dims(Y_val, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq01DK9xi3dt"
      },
      "source": [
        "**2.4. Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2O_pgTxi32D",
        "outputId": "cdda3a25-f0bd-446b-f0ca-fc42347172ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.7775 - loss: 0.7885 - val_accuracy: 0.8456 - val_loss: 0.3518\n",
            "Epoch 2/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8588 - loss: 0.3341 - val_accuracy: 0.8976 - val_loss: 0.2548\n",
            "Epoch 3/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9189 - loss: 0.2101 - val_accuracy: 0.9565 - val_loss: 0.1226\n",
            "Epoch 4/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9682 - loss: 0.0936 - val_accuracy: 0.9943 - val_loss: 0.0323\n",
            "Epoch 5/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9951 - loss: 0.0261 - val_accuracy: 0.9994 - val_loss: 0.0092\n",
            "Epoch 6/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0075 - val_accuracy: 0.9996 - val_loss: 0.0054\n",
            "Epoch 7/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
            "Epoch 8/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 9/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 8.6153e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0847e-04 - val_accuracy: 1.0000 - val_loss: 6.9570e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.1388e-04 - val_accuracy: 1.0000 - val_loss: 5.7454e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.9872e-04 - val_accuracy: 1.0000 - val_loss: 5.3962e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2305e-04 - val_accuracy: 1.0000 - val_loss: 4.1672e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6274e-04 - val_accuracy: 1.0000 - val_loss: 3.6899e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.2321e-04 - val_accuracy: 0.9999 - val_loss: 3.1080e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.8883e-04 - val_accuracy: 0.9999 - val_loss: 4.1492e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.5994e-04 - val_accuracy: 0.9999 - val_loss: 3.7337e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.3362e-04 - val_accuracy: 0.9999 - val_loss: 3.1544e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1582e-04 - val_accuracy: 0.9999 - val_loss: 3.7545e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7741e-05 - val_accuracy: 0.9999 - val_loss: 4.0839e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.1943e-05 - val_accuracy: 0.9999 - val_loss: 2.1171e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 7.1351e-05 - val_accuracy: 0.9999 - val_loss: 3.8250e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.2255e-05 - val_accuracy: 1.0000 - val_loss: 2.9199e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4769e-05 - val_accuracy: 0.9999 - val_loss: 2.9708e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.7631e-05 - val_accuracy: 0.9999 - val_loss: 3.4588e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.2416e-05 - val_accuracy: 0.9999 - val_loss: 2.9664e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.7725e-05 - val_accuracy: 0.9999 - val_loss: 2.5851e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.4139e-05 - val_accuracy: 0.9999 - val_loss: 2.5037e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.1114e-05 - val_accuracy: 1.0000 - val_loss: 3.1992e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6879e-05 - val_accuracy: 1.0000 - val_loss: 1.7839e-04\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    [X_train, decoder_input_train],\n",
        "    Y_train_expanded,\n",
        "    validation_data=([X_val, decoder_input_val], Y_val_expanded),\n",
        "    epochs=30,\n",
        "    batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnnxxb52j0t-"
      },
      "source": [
        "# Step 3: Autoregressive Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tk9gwL_kDuI"
      },
      "source": [
        "**3.1. Define Inference Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "B3oAHGlukAsJ"
      },
      "outputs": [],
      "source": [
        "# Encoder model (used for inference)\n",
        "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Inputs for inference step\n",
        "decoder_input_single = Input(shape=(1,), name='decoder_input_single')  # single token input\n",
        "decoder_state_input_h = Input(shape=(LATENT_DIM,), name='decoder_state_input_h')\n",
        "decoder_state_input_c = Input(shape=(LATENT_DIM,), name='decoder_state_input_c')\n",
        "encoder_outputs_input = Input(shape=(MAX_LEN, LATENT_DIM), name='encoder_outputs_input')  # full encoder sequence\n",
        "\n",
        "# Embedding for current input token\n",
        "decoder_embed_inf = embedding_layer(decoder_input_single)  # shape: (1, 1, EMBEDDING_DIM)\n",
        "\n",
        "# Run decoder LSTM for one timestep\n",
        "decoder_lstm_output, state_h_inf, state_c_inf = decoder_lstm(\n",
        "    decoder_embed_inf, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        ")  # output shape: (1, 1, LATENT_DIM)\n",
        "\n",
        "# Attention scores = dot product between decoder output and encoder outputs\n",
        "attention_scores = Dot(axes=[2, 2], name='attention_scores')(\n",
        "    [decoder_lstm_output, encoder_outputs_input]\n",
        ")  # shape: (1, 1, T_enc)\n",
        "\n",
        "# Normalize scores to probabilities\n",
        "attention_weights = Activation('softmax', name='attention_weights')(attention_scores)  # shape: (1, 1, T_enc)\n",
        "\n",
        "# Weighted sum of encoder outputs (context vector)\n",
        "context_vector = Dot(axes=[2, 1], name='context_vector')(\n",
        "    [attention_weights, encoder_outputs_input]\n",
        ")  # shape: (1, 1, LATENT_DIM)\n",
        "\n",
        "# Concatenate decoder output + context\n",
        "decoder_context_combined = Concatenate(axis=-1, name='decoder_context_concat')(\n",
        "    [decoder_lstm_output, context_vector]\n",
        ")  # shape: (1, 1, 2*LATENT_DIM)\n",
        "\n",
        "# Project to vocabulary\n",
        "decoder_output_inf = output_layer(decoder_context_combined)  # shape: (1, 1, VOCAB_SIZE)\n",
        "\n",
        "# Final decoder inference model\n",
        "decoder_model = Model(\n",
        "    inputs=[\n",
        "        decoder_input_single,\n",
        "        decoder_state_input_h,\n",
        "        decoder_state_input_c,\n",
        "        encoder_outputs_input\n",
        "    ],\n",
        "    outputs=[\n",
        "        decoder_output_inf,\n",
        "        state_h_inf,\n",
        "        state_c_inf\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vclFWhLlkHdC"
      },
      "source": [
        "**3.2. Autoregressive Decode Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "whhkXkfikKmk"
      },
      "outputs": [],
      "source": [
        "def autoregressive_decode_with_attention(input_seq):\n",
        "    # Encode the input\n",
        "    enc_outputs, h, c = encoder_model.predict(input_seq.reshape(1, -1), verbose=0)\n",
        "\n",
        "    target_seq = np.zeros((1, 1), dtype=np.int32)\n",
        "    target_seq[0, 0] = SOS_ID\n",
        "\n",
        "    decoded_tokens = []\n",
        "\n",
        "    for _ in range(MAX_LEN):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, h, c, enc_outputs], verbose=0\n",
        "        )\n",
        "        sampled_token_index = np.argmax(output_tokens[0, 0])\n",
        "        sampled_token = id_to_token[sampled_token_index]\n",
        "\n",
        "        if sampled_token == 'EOS':\n",
        "            break\n",
        "        decoded_tokens.append(sampled_token)\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # Convert to ID format\n",
        "    return [token_to_id[t] for t in decoded_tokens if t in token_to_id]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2WW4GElkNMQ"
      },
      "source": [
        "**3.3. Try an Example**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YNKE1yRkNl1",
        "outputId": "d067d344-ef22-4dbc-e80c-d5e7249d8c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infix        : ( ( d * e ) / ( a - ( e / a ) ) )\n",
            "Target Postfix: d e * a e a / - /\n",
            "Predicted     : d e * a e a / - /\n"
          ]
        }
      ],
      "source": [
        "idx = np.random.randint(len(X_val))\n",
        "x_sample = X_val[idx]\n",
        "y_true = Y_val[idx]\n",
        "y_pred = autoregressive_decode_with_attention(x_sample)\n",
        "\n",
        "print(\"Infix        :\", decode_sequence(x_sample, id_to_token))\n",
        "print(\"Target Postfix:\", decode_sequence(y_true, id_to_token))\n",
        "print(\"Predicted     :\", decode_sequence(y_pred, id_to_token))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52E8gL7ekyBK"
      },
      "source": [
        "# Step 4: Prefix Accuracy Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cOkw7cykyc5"
      },
      "source": [
        "**4.1. Function: prefix_accuracy_single**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "AtbteDDrky3J"
      },
      "outputs": [],
      "source": [
        "def prefix_accuracy_single(y_true, y_pred, id_to_token, eos_id=EOS_ID, verbose=False):\n",
        "    t_str = decode_sequence(y_true, id_to_token).split(' EOS')[0]\n",
        "    p_str = decode_sequence(y_pred, id_to_token).split(' EOS')[0]\n",
        "    t_tokens = t_str.strip().split()\n",
        "    p_tokens = p_str.strip().split()\n",
        "\n",
        "    max_len = max(len(t_tokens), len(p_tokens))\n",
        "    match_len = sum(x == y for x, y in zip(t_tokens, p_tokens))\n",
        "\n",
        "    score = match_len / max_len if max_len > 0 else 0\n",
        "\n",
        "    if verbose:\n",
        "        print(\"TARGET  :\", ' '.join(t_tokens))\n",
        "        print(\"PREDICT :\", ' '.join(p_tokens))\n",
        "        print(f\"MATCH   : {match_len}/{max_len} → {score:.2f}\")\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEoJ6TdVlP1Y"
      },
      "source": [
        "**4.2. Function: test()**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rwIRrb0glQJp"
      },
      "outputs": [],
      "source": [
        "def test(n=20, rounds=5):\n",
        "    results = []\n",
        "    for r in range(rounds):\n",
        "        print(f\"Round {r+1}\")\n",
        "        X_test, Y_test = generate_dataset(n)\n",
        "        scores = []\n",
        "        for i in range(n):\n",
        "            x = X_test[i]\n",
        "            y_true = Y_test[i]\n",
        "            y_pred = autoregressive_decode_with_attention(x)\n",
        "            score = prefix_accuracy_single(y_true, y_pred, id_to_token)\n",
        "            scores.append(score)\n",
        "        avg = np.mean(scores)\n",
        "        print(f\"  Average prefix accuracy: {avg:.3f}\")\n",
        "        results.append(avg)\n",
        "    return np.mean(results), np.std(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2MH4vKMlFGW"
      },
      "source": [
        "**4.3. Run Evaluationt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHLe8G72lFYn",
        "outputId": "e99183b0-8e79-4da2-ac97-f2b14d58558e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 2\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 3\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 4\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 5\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 6\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 7\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 8\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 9\n",
            "  Average prefix accuracy: 1.000\n",
            "Round 10\n",
            "  Average prefix accuracy: 1.000\n",
            "\n",
            "Final Prefix Accuracy: 1.000 ± 0.000\n"
          ]
        }
      ],
      "source": [
        "mean_score, std_dev = test(n=20, rounds=10)\n",
        "print(f\"\\nFinal Prefix Accuracy: {mean_score:.3f} ± {std_dev:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new unseen test dataset\n",
        "X_test_new, Y_test_new = generate_dataset(n=1000, max_depth=MAX_DEPTH)\n",
        "def evaluate_on_dataset(X_data, Y_data, sample_count=20, verbose=False):\n",
        "    scores = []\n",
        "    for i in range(sample_count):\n",
        "        x = X_data[i]\n",
        "        y_true = Y_data[i]\n",
        "        y_pred = autoregressive_decode_with_attention(x)\n",
        "        score = prefix_accuracy_single(y_true, y_pred, id_to_token, verbose=verbose)\n",
        "        scores.append(score)\n",
        "    return np.mean(scores), np.std(scores)\n",
        "mean_new, std_new = evaluate_on_dataset(X_test_new, Y_test_new, sample_count=100, verbose=False)\n",
        "print(f\"New Test Set Prefix Accuracy: {mean_new:.3f} ± {std_new:.3f}\")\n",
        "for _ in range(5):\n",
        "    i = np.random.randint(len(X_test_new))\n",
        "    print(f\"\\nExample {i}\")\n",
        "    print(\"Infix       :\", decode_sequence(X_test_new[i], id_to_token))\n",
        "    print(\"True Postfix:\", decode_sequence(Y_test_new[i], id_to_token))\n",
        "    print(\"Predicted   :\", decode_sequence(autoregressive_decode_with_attention(X_test_new[i]), id_to_token))\n",
        "    print('-' * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHo0duZkLWOS",
        "outputId": "ae2eff2b-d37e-47ab-d613-1b6c8abe526f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Test Set Prefix Accuracy: 0.998 ± 0.020\n",
            "\n",
            "Example 402\n",
            "Infix       : ( ( ( a + d ) / ( b / a ) ) / ( ( a - e ) + ( e + d ) ) )\n",
            "True Postfix: a d + b a / / a e - e d + + /\n",
            "Predicted   : a d + b a / / a e - e d + + /\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 51\n",
            "Infix       : ( ( ( d + b ) + ( e + c ) ) + ( d / b ) )\n",
            "True Postfix: d b + e c + + d b / +\n",
            "Predicted   : d b + e c + + d b / +\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 646\n",
            "Infix       : ( ( ( a / c ) + ( c - c ) ) * b )\n",
            "True Postfix: a c / c c - + b *\n",
            "Predicted   : a c / c c - + b *\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 820\n",
            "Infix       : ( a + ( b + ( a + b ) ) )\n",
            "True Postfix: a b a b + + +\n",
            "Predicted   : a b a b + + +\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 854\n",
            "Infix       : ( d / ( d - b ) )\n",
            "True Postfix: d d b - /\n",
            "Predicted   : d d b - /\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}